{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EDA pkgs\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Load Data Vis Pkg\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "# Load ML Pkgs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For Neural network (MultiLayerPerceptron)\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety  class\n",
       "0  vhigh  vhigh     2       2    small    low  unacc\n",
       "1  vhigh  vhigh     2       2    small    med  unacc\n",
       "2  vhigh  vhigh     2       2    small   high  unacc\n",
       "3  vhigh  vhigh     2       2      med    low  unacc\n",
       "4  vhigh  vhigh     2       2      med    med  unacc"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['buying','maint','doors' ,'persons','lug_boot','safety','class']\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data/carData.csv\",names=col_names)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then label-encode our data set using either of these methods:\n",
    "\n",
    "1. Custom Function\n",
    "2. Label Encoder from Sklearn\n",
    "3. OneHot Encoding\n",
    "4. Pandas Get Dummies\n",
    "\n",
    "In our Case we will be using a custom function to help us encode our data set and then map them to our values for each column respectively. We will then save these labels as dictionaries and use it for building the options sections of our ML app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Function\n",
    "buying_label = { ni: n for n,ni in enumerate(set(df['buying']))}\n",
    "maint_label = { ni: n for n,ni in enumerate(set(df['maint']))}\n",
    "doors_label = { ni: n for n,ni in enumerate(set(df['doors']))}\n",
    "persons_label = { ni: n for n,ni in enumerate(set(df['persons']))}\n",
    "lug_boot_label = { ni: n for n,ni in enumerate(set(df['lug_boot']))}\n",
    "safety_label = { ni: n for n,ni in enumerate(set(df['safety']))}\n",
    "class_label = { ni: n for n,ni in enumerate(set(df['class']))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['buying'] = df1['buying'].map(buying_label)\n",
    "df1['maint'] = df1['maint'].map(maint_label)\n",
    "df1['doors'] = df1['doors'].map(doors_label)\n",
    "df1['persons'] = df1['persons'].map(persons_label)\n",
    "df1['lug_boot'] = df1['lug_boot'].map(lug_boot_label)\n",
    "df1['safety'] = df1['safety'].map(safety_label)\n",
    "df1['class'] = df1['class'].map(class_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the label encoder option\n",
    "\n",
    "###### Using LabelEncoder\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb=LabelEncoder()\n",
    "\n",
    "df2 = df\n",
    "\n",
    "for i in df2.columns:\n",
    "\n",
    "df2[i]=lb.fit_transform(df2[i])\n",
    "\n",
    "### Building the Model\n",
    "\n",
    "To summarize we will be using 3 different ML algorithms\n",
    "\n",
    "1. LogisticRegression\n",
    "2. Naive Bayes\n",
    "3. Multi-Layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our dataset into training and test dataset\n",
    "Xfeatures = df1[['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']]\n",
    "ylabels = df1['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xfeatures, ylabels, test_size=0.30, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using LogisticRegression\n",
    "\n",
    "logit = LogisticRegression()\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7148362235067437\n"
     ]
    }
   ],
   "source": [
    "# We can then check for the accuracy of our model using accuracy_score from sklearn.metrics.\n",
    "print(\"Accuracy Score:\",accuracy_score(y_test, logit.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dkonigiri/Documents/ML/general/env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Neural Network\n",
    "\n",
    "nn_clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "nn_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
    "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "              hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
    "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
    "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
    "              power_t=0.5, random_state=1, shuffle=True, solver='lbfgs',\n",
    "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "              warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8497109826589595\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score:\",accuracy_score(y_test, nn_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model For Our App\n",
    "\n",
    "To build our ML app we will need to save or serialized our ML models and use them for the next section. You can use pickle or joblib, but you should make sure to use the same when loading/de-serializing your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Models\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = open(\"logit_car_model.pkl\",\"wb\")\n",
    "joblib.dump(logit,logit_model)\n",
    "logit_model.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_clf_model = open(\"nn_clf_car_model.pkl\",\"wb\")\n",
    "joblib.dump(nn_clf,nn_clf_model)\n",
    "nn_clf_model.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
